{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 개요\n",
    "\n",
    "- Agent 대형 언어 모델(LLM)과 다양한 도구(Tool)를 결합하여 복잡한 작업을 처리할 수 있도록 설계된 사용자 요청 처리 인공지능 시스템이다.\n",
    "    - Agent는 주어진 목표를 달성하기 위해 환경(toolkit)과 상호작용하며 의사 결정을 내리고 행동을 취하는 자율적인 개체이다.\n",
    "    - Agent의 자율적인 의사 결정은 LLM 이 담당하여 사람의 개입이 최소화 된다.\n",
    "\n",
    "## Agent의 주요 특징\n",
    "- **자율성**: 사전 정의된 규칙 없이도 스스로 결정을 내리고 행동할 수 있다.\n",
    "- **목표 지향성**: 특정 목표나 작업을 달성하기 위해 설계되어 있다.\n",
    "- **도구 활용**: 다양한 도구나 API를 활용하여 작업을 수행한다.\n",
    "\n",
    "## Agent 기본 동작 원리\n",
    "\n",
    "![agent_concept](figures/agent_concept.png)\n",
    "\n",
    "### ReAct\n",
    "- Reasoning and Acting의 약자로, 에이전트가 문제를 해결할 때 추론과 행동을 결합하는 방식이다.\n",
    "\n",
    "#### 동작 단계\n",
    "- **사용자 입력 수신**: \n",
    "    - 에이전트는 사용자가 입력한 질문이나 명령을 받는다.\n",
    "- **추론(Reasoning)**\n",
    "    - 입력된 내용을 분석하여 문제를 이해하고, 해결 방안을 계획합니다. \n",
    "- **행동 결정 및 도구 실행(Action)**: \n",
    "    - 계획에 따라 어떤 도구를 사용할지 결정하고 그 도구를 호출하여 작업을 수행한다.\n",
    "- **결과 평가 및 추가 행동 결정**: \n",
    "    - 도구 실행 결과를 바탕으로 추가로 도구를 사용할지, 아니면 최종 답변을 생성할지를 결정한다.\n",
    "    - 추가로 도구를 사용하기로 결정한 경우 도구를 실행한다.\n",
    "- **최종 답변 반환**: \n",
    "    - 최종 결과를 사용자에게 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOOL\n",
    "- **Tool은 하나의 기능을 처리하는 함수이다.**\n",
    "\n",
    "## Tool Calling 개요\n",
    "- LLM이 외부 도구나 API를 활용하여 작업을 수행할 수 있게 하는 기능이다.\n",
    "    1. LLM 이 사용할 수 있는 도구들을 binding한다.\n",
    "    2. 사용자로 부터 질의가 들어오면 그 질의를 처리하기 위해 tool을 호출 하는 것이 필요하다면 LLM은 어떤 tool을 어떻게 호출할지 응답한다.\n",
    "    3.  사용자는 응답에 맞는 tool을 호출하고 그 처리결과를 취합해 질의와 함께 LLM에게 요청한다.\n",
    "\t- TOOL Calling 예\n",
    "        - LLM이 수학 계산을 수행해야 할 때, 직접 계산하는 대신 미리 정의된 '계산' 도구를 호출하여 정확한 결과를 얻을 수 있다.\n",
    "    \t- LLM에 최신 정보를 요청하는 질문이 들어왔을 때 '검색' 도구나 'Database 연동' 도구를 사용해 최신 뉴스를 검색하거나, 특정 데이터베이스에서 정보를 조회하는 등의 작업을 수행할 수 있다.\n",
    "- **LLM은 도구를 이용해 자체 지식의 한계를 넘어서는 정보를 제공할 수 있습니다.**\n",
    "- Tool calling은 OpenAI, Anthropic 등 여러 LLM 서비스가 지원한다.\n",
    "  - Tool Calling을 지원하는 LLM 모델만 사용할 수있다.\n",
    "- LangChain은 다양한 모델들의 도구 호출 방식을 표준화하여 일관된 인터페이스로 제공한다. 이를 통해 개발자들은 다양한 모델과 도구들을 쉽게 통합할 수있다.\n",
    "- Tool Calling Concept: https://python.langchain.com/docs/concepts/tool_calling/\n",
    "- Langchain 지원 tools (Builtin Tool)\n",
    "    -  https://python.langchain.com/docs/integrations/tools/#search\n",
    "- **Agent:**\n",
    "\t- LLM 모델이 목표한 결과를 얻기 위해 적절한 도구를 선택하고, 이를 활용하여 작업을 수행하는 시스템을 **Agent**라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랭체인 내장 도구(tools) 사용\n",
    "- Langchain은 다양한 도구들을 구현해서 제공하고 있다. 이것들을 builtin tool이라고 한다. \n",
    "  - [Langchain 지원 Built tools](https://python.langchain.com/docs/integrations/tools/)\n",
    "- 그 외에 필요한 도구들을 직접 구현할 수있는 방법도 제공한다.\n",
    "- Tavily 웹 검색 도구 사용해 Tool calling을 이해한다.\n",
    "\n",
    "\n",
    "## Tavily\n",
    "- LLM을 위한 웹 검색 API.\n",
    "- https://tavily.com/\n",
    "-  LLM과 RAG 시스템에 최적화된 검색 엔진.\n",
    "   -  기존의 일반 검색 엔진들과 달리, Tavily는 AI 애플리케이션의 요구사항에 맞춰 설계되었다.\n",
    "   -  Tavily는 검색 결과에서 검색 query와 관련 콘텐츠를 추출하여 제공한다.\n",
    "   -  월 1000회 무료 사용 가능.\n",
    "### Tavily API Key 받기\n",
    "- 로그인 한다.\n",
    "- Overview 화면에서 API Key 생성  \n",
    "- **API Keys \\[+\\] 클릭**\n",
    "\n",
    "![apikey1](figures/travily_apikey1.png)\n",
    "\n",
    "- **Key Name을 입력하고 생성**\n",
    "\n",
    "![apikey1](figures/travily_apikey2.png)\n",
    "\n",
    "- **API Key를 복사**\n",
    "\n",
    "![apikey1](figures/travily_apikey3.png)\n",
    "\n",
    "- 환경변수에 등록한다.\n",
    "    - 변수이름: \"TAVILY_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TavilySearch\n",
    "- Langchain에서 제공하는 tool로 Tavily 의 검색 엔진 API를 사용해 검색을 수행한다.\n",
    "- 설치\n",
    "  - `pip install langchain-tavily`\n",
    "- https://python.langchain.com/docs/integrations/tools/tavily_search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM tool callings\n",
    "\n",
    "### 작동 원리\n",
    "\n",
    "![toolcalling_concept](figures/toolcalling_concept.png)\n",
    "1. Tool 생성\n",
    "2. 생성한 Tool을 tool calling을 지원하는 LLM 모델에 연결(binding)\n",
    "   - LLM 이 사용할 수있는 tool들을 등록(bind) 한다.\n",
    "    - **`Model.bind([tool_1, tool_2, ...]): RunnableBinding`**\n",
    "    - Model에 tool을 bind 하면 `Runnable` 타입의 `RunnableBinding` 객체가 반환된다.\n",
    "3. 질의가 들어오면 모델(LLM + tool) 은 tool calling 정보(어떤 툴을 어떤 query로 호출할지 schema 에 맞게 만든 정보)를 응답.\n",
    "    - 질의에 대해 tool 요청이 **필요하다고** 결정한 경우 tool들 중 어떤 tool을 어떤 query로 호출해야 하는지를 응답한다.\n",
    "    - 질의에 대해 tool 요청이 **필요 없다고** 결정한 경우는 LLM API를 호출한다.(모델이 직접 응답)\n",
    "5. 3에서 응답한 tool calling 정보를 이용해 tool 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Model에 tool binding\n",
    "- `LLM.bind_tools(tools=[tool_1, tool_2, ...])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tool_calls 를 이용해 Tool 호출\n",
    "- LLM 모델이 tool 요청을 결정한 경우 어떤 tool을 어떻게 호출할 지 tool_calls를 반환한다.\n",
    "- tool_calls를 이용해 Tool을 호출한다.\n",
    "\n",
    "### 방법\n",
    "1. `tool_calls` 의 `args` 값을 전달.\n",
    "   - `args`는 tool을 호출(invoke)할 때 전달할 정보를 dictionary로 제공한다.\n",
    "   - `tool.invoke(result.tool_calls[0]['args'])`\n",
    "   - **반환타입**: 각 tool의 반환타입\n",
    "2. tool_calls 정보를 넣어 호출\n",
    "   - `tool.invoke(result.tool_calls[0])`\n",
    "   - **반환타입**: `ToolMessage`\n",
    "     - Tool의 처리결과를 담는 Message Type 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tool_calls의 args를 이용해 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tool_call 정보를 넣어 Tool 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tool_call 이 여러개일 경우 \n",
    "- 질의에 대해 tool을 여러번 호출 해야 하는 경우 tool_calling 정보를 여러개 반환할 수 있다.\n",
    "    - 예) 검색할 키워드가 여러개인 경우. \n",
    "- `tool.batch([tool_call1, tool_call2, ..])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 의 처리(응답) 결과를 LLM 요청시 사용\n",
    "- ToolMessage를 prompt 에 추가하여 LLM에 요청한다.\n",
    "- ToolMessage 는 Tool Calling 정보를 가진 AIMessage 다음에 들어와야 한다.\n",
    "- Prompt 순서\n",
    "    1. 일반 prompt (system, 대화 history, .., human)\n",
    "    2. AIMessage: tool calling 정보를 가진 AIMessage. (tool_model에 질의 받은 tool calling 정보가 있는 응답)\n",
    "    3. ToolMessage:  Tool의 처리 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자 정의 Tool 구현\n",
    "\n",
    "## @tool 사용\n",
    "- 함수로 구현하고 `@tool` 데코레이터를 사용해 tool(StructuredTool)로 정의한다.\n",
    "    - `langchain_core.tools` 모듈에 있다.\n",
    "- tool name\n",
    "    - 함수의 이름이 tool의 이름이 된다.\n",
    "- parameters\n",
    "    - 함수의 파라미터가 tool의 파라미터가 된다.\n",
    "    - **type hint**를 이용해 타입을 지정한다.  \n",
    "- description\n",
    "    - doctring이 description이 된다.\n",
    "    - RunnableBinding이 tool을 잘 찾을 수 있도록 하려면 **tool의 기능을 최대한 구체적**으로 작성한다.\n",
    "- **@tool이 적용된 함수(StructuredTool)이 tool**이므로 model에 binding 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable을 tool로 정의\n",
    "- `Runnable객체.as_tool()`\n",
    "    - name, description, args_schema 파라미터를 이용해 tool의 이름, 설명, 스키마를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store(Vector 저장소) tool\n",
    "\n",
    "### text loading -> Document 생성\n",
    "- 레스토랑 메뉴를 vector store에 저장한다.\n",
    "1. 메뉴 text 를 로딩한다.\n",
    "2. 각 메뉴의 내용(음식이름, 메뉴설명, 파일명)을 넣어 Document를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 구현\n",
    "\n",
    "- `create_tool_calling_agent()` 를 이용해 Agent 생성\n",
    "    - 파라미터\n",
    "        - llm: 에이전트로 사용할 LLM.\n",
    "        - tools: 에이전트가 접근할 수 있는 도구들의 목록.\n",
    "        - prompt_template: 에이전트의 동작을 안내하는 프롬프트 템플릿.\n",
    "            - 이름이 `agent_scratchpad` 인 MessagesPlaceholder 추가\n",
    "                - Agent 가 tool을 호출해서 받은 정보를 prompt에 추가하는 placeholder.\n",
    "- AgentExecutor를 이용해 Agent 실행\n",
    "    - Agent의 동작을 관리하는 클래스.\n",
    "    - AgentExecutor는 사용자 요청을 처리할 때 까지 적절한 tool들을 호출하고 최종 결과를 생성해 반환하는 작업을 처리한다.\n",
    "    - 파라미터\n",
    "        - agent: 실행할 Agent.\n",
    "        - tools: Agent가 사용할 tool들 목록."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
